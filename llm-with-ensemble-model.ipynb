{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4b4ff4",
   "metadata": {
    "papermill": {
     "duration": 0.011594,
     "end_time": "2024-01-14T05:30:44.748886",
     "exception": false,
     "start_time": "2024-01-14T05:30:44.737292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "üåü **Welcome to the AI-Generated Text Detection Notebook** üåü\n",
    "\n",
    "\n",
    "### Inspiration and Credits üôå\n",
    "This notebook is inspired by the work of Prem Chotepanit, available at [this Kaggle project]( https://www.kaggle.com/code/batprem/llm-daigt-analyse-edge-cases). I extend my gratitude to Prem Chotepanit for sharing their insights and code.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ How the Notebook Works:\n",
    "\n",
    "- **Data Loading:** Initial cell loads essential libraries and imports data from various CSV files.\n",
    "  \n",
    "- **Text Tokenization:** Utilizes Byte-Pair Encoding (BPE) for tokenization, creating a robust representation of text.\n",
    "\n",
    "- **TF-IDF Vectorization:** Implements TF-IDF vectorization on the tokenized texts, capturing important features.\n",
    "\n",
    "- **Model Training:** Constructs an ensemble of machine learning models (Multinomial Naive Bayes, SGD, LightGBM, CatBoost) to achieve optimal predictions.\n",
    "\n",
    "- **Submission Generation:** Generates predictions and outputs a submission file ('submission.csv').\n",
    "\n",
    "---\n",
    "\n",
    "### üôè Thanks to the Competition Host:\n",
    "\n",
    "- A heartfelt thanks to the competition host for providing the opportunity to work on this fascinating task.\n",
    "\n",
    "---\n",
    "\n",
    "### üì¨ Feedback and Gratitude:\n",
    "\n",
    "- Your feedback is invaluable! If you find this notebook helpful or have suggestions for improvement, please share your thoughts. Your insights contribute to a collaborative learning environment.\n",
    "\n",
    "- Thanks for exploring this notebook. Good luck with your AI-generated text detection journey!\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ca3c1",
   "metadata": {
    "papermill": {
     "duration": 0.010708,
     "end_time": "2024-01-14T05:30:44.770675",
     "exception": false,
     "start_time": "2024-01-14T05:30:44.759967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üñ•Ô∏è Importing Libraries¬∂\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e14fa1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:44.794420Z",
     "iopub.status.busy": "2024-01-14T05:30:44.794058Z",
     "iopub.status.idle": "2024-01-14T05:30:54.396836Z",
     "shell.execute_reply": "2024-01-14T05:30:54.396029Z"
    },
    "papermill": {
     "duration": 9.617346,
     "end_time": "2024-01-14T05:30:54.399183",
     "exception": false,
     "start_time": "2024-01-14T05:30:44.781837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import pandas, a library for data analysis and manipulation üêº\n",
    "import pandas as pd\n",
    "\n",
    "# Import json, a library for working with JSON data format üìÑ\n",
    "import json\n",
    "\n",
    "# Import sys, a library for accessing system-specific parameters and functions üñ•Ô∏è\n",
    "import sys\n",
    "\n",
    "# Import gc, a library for controlling the garbage collector üóëÔ∏è\n",
    "import gc\n",
    "\n",
    "# Import StratifiedKFold, a class for performing stratified k-fold cross-validation üßÆ\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Import numpy, a library for scientific computing and linear algebra üßÆ\n",
    "import numpy as np\n",
    "\n",
    "# Import roc_auc_score, a function for computing the area under the receiver operating characteristic curve üìà\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Import LGBMClassifier, a class for training and using LightGBM models üå≥\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Import TfidfVectorizer, a class for transforming text into TF-IDF features üìù\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import various classes and functions from the tokenizers library, which is used for creating and using custom tokenizers üó£Ô∏è\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "# Import Dataset, a class for working with datasets in a standardized way üóÉÔ∏è\n",
    "from datasets import Dataset\n",
    "\n",
    "# Import tqdm, a library for displaying progress bars ‚è≥\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Import PreTrainedTokenizerFast, a class for using fast tokenizers from the transformers library üöÄ\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# Import SGDClassifier, a class for training and using stochastic gradient descent models üìâ\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Import MultinomialNB, a class for training and using multinomial naive Bayes models üé≤\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Import VotingClassifier, a class for combining multiple classifiers into a single one üó≥Ô∏è\n",
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338d304",
   "metadata": {
    "papermill": {
     "duration": 0.010883,
     "end_time": "2024-01-14T05:30:54.421693",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.410810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explaination:\n",
    "\n",
    "The edge_cases dataframe contains some examples of text that might be challenging for a machine learning model to classify correctly. For instance, some texts are sarcastic, ambiguous, or contain typos. ü§î\n",
    "\n",
    "You can use this dataframe to test the performance of your model on these edge cases and see how well it handles them. üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c8eedf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:54.446180Z",
     "iopub.status.busy": "2024-01-14T05:30:54.445153Z",
     "iopub.status.idle": "2024-01-14T05:30:54.486694Z",
     "shell.execute_reply": "2024-01-14T05:30:54.485739Z"
    },
    "papermill": {
     "duration": 0.055868,
     "end_time": "2024-01-14T05:30:54.488697",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.432829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33895</td>\n",
       "      <td>First impressions are a crucial aspect of our...</td>\n",
       "      <td>0.410707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39951</td>\n",
       "      <td>As an eighth-grade student, I possess a talent...</td>\n",
       "      <td>0.413961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26725</td>\n",
       "      <td>Ummm... hey there!  So, umm... Winston Churchi...</td>\n",
       "      <td>0.467152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35647</td>\n",
       "      <td>\"When you are doing something wrong and someo...</td>\n",
       "      <td>0.356944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27976</td>\n",
       "      <td>I believe that working 10 hours a day is more...</td>\n",
       "      <td>0.450531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>26115</td>\n",
       "      <td>Cell phones have become a hot topic when it co...</td>\n",
       "      <td>0.490097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>29732</td>\n",
       "      <td>Honesty is a virtue that is often associated ...</td>\n",
       "      <td>0.331009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>36240</td>\n",
       "      <td>The advantages of limiting car usage are becom...</td>\n",
       "      <td>0.473156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>39819</td>\n",
       "      <td>Drivers Should Not Use Cell Phones in Any Capa...</td>\n",
       "      <td>0.419902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>35456</td>\n",
       "      <td>According to the National Center for Education...</td>\n",
       "      <td>0.430731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  prediction  \\\n",
       "0    33895   First impressions are a crucial aspect of our...    0.410707   \n",
       "1    39951  As an eighth-grade student, I possess a talent...    0.413961   \n",
       "2    26725  Ummm... hey there!  So, umm... Winston Churchi...    0.467152   \n",
       "3    35647   \"When you are doing something wrong and someo...    0.356944   \n",
       "4    27976   I believe that working 10 hours a day is more...    0.450531   \n",
       "..     ...                                                ...         ...   \n",
       "165  26115  Cell phones have become a hot topic when it co...    0.490097   \n",
       "166  29732   Honesty is a virtue that is often associated ...    0.331009   \n",
       "167  36240  The advantages of limiting car usage are becom...    0.473156   \n",
       "168  39819  Drivers Should Not Use Cell Phones in Any Capa...    0.419902   \n",
       "169  35456  According to the National Center for Education...    0.430731   \n",
       "\n",
       "     generated  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "..         ...  \n",
       "165          1  \n",
       "166          1  \n",
       "167          1  \n",
       "168          1  \n",
       "169          1  \n",
       "\n",
       "[170 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the edge_cases.csv file from the given path using pandas üêº\n",
    "edge_cases = pd.read_csv(\"/kaggle/input/llm-daigt-find-edge-case/edge_cases.csv\")\n",
    "\n",
    "# Display the edge_cases dataframe using pandas üóÉÔ∏è\n",
    "edge_cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd14def",
   "metadata": {
    "papermill": {
     "duration": 0.011478,
     "end_time": "2024-01-14T05:30:54.512169",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.500691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explanation \n",
    "\n",
    "An array of unique values present in the \"generated\" column, such as \"positive,\" \"negative,\" or \"neutral.\" This can be insightful for understanding the distribution of classes in your data.\n",
    "\n",
    "- Use this information to analyze how many distinct classes are present in your dataset and explore the balance among them. üßÆ\n",
    "\n",
    "**Sources:**\n",
    "1. [Stack Overflow - Difference between an edge case and a corner case](https://stackoverflow.com/questions/47560177/what-is-the-difference-between-an-edge-case-and-a-corner-case).\n",
    "2. [Stack Overflow - Edge cases in unit testing](https://stackoverflow.com/questions/4718862/are-these-the-sort-of-edge-cases-i-should-think-of-when-using-unit-testing).\n",
    "3. [TestSigma - Understanding Edge Case Testing](https://testsigma.com/blog/edge-case-testing/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfdc2a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:54.536651Z",
     "iopub.status.busy": "2024-01-14T05:30:54.536134Z",
     "iopub.status.idle": "2024-01-14T05:30:54.544041Z",
     "shell.execute_reply": "2024-01-14T05:30:54.543191Z"
    },
    "papermill": {
     "duration": 0.022261,
     "end_time": "2024-01-14T05:30:54.545981",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.523720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the unique method of pandas to get the unique values of the \"generated\" column in the edge_cases dataframe üêº\n",
    "edge_cases[\"generated\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc73a0",
   "metadata": {
    "papermill": {
     "duration": 0.011757,
     "end_time": "2024-01-14T05:30:54.569964",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.558207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explanation \n",
    "\n",
    "Generates a tuple of four numbers, providing insights into the range and distribution of prediction values within the \"edge_cases\" dataframe.\n",
    "\n",
    "- Analyze the tuple to assess the accuracy of your model on edge cases and understand the variability in predictions. üßÆ\n",
    "\n",
    "**Sources:**\n",
    "1. [LogRocket - What is an edge case? Meaning, examples in software development](https://blog.logrocket.com/product-management/edge-case-software-development/).\n",
    "2. [Stack Overflow - Difference between an edge case and a corner case](https://stackoverflow.com/questions/47560177/what-is-the-difference-between-an-edge-case-and-a-corner-case).\n",
    "3. [Applause - How to Find and Test Edge Cases](https://www.applause.com/blog/how-to-find-test-edge-cases).\n",
    "4. [Wikipedia - Edge case](https://en.wikipedia.org/wiki/Edge_case).\n",
    "5. [Mindful QA - What Are Edge Cases in Software Testing?](https://www.mindfulqa.com/edge-cases/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d254e930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:54.595469Z",
     "iopub.status.busy": "2024-01-14T05:30:54.595173Z",
     "iopub.status.idle": "2024-01-14T05:30:54.604881Z",
     "shell.execute_reply": "2024-01-14T05:30:54.603979Z"
    },
    "papermill": {
     "duration": 0.025042,
     "end_time": "2024-01-14T05:30:54.607042",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.582000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.40149828802332427, 0.4246961745658604, 0.4985209873471804)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the min, mean, median, and max methods of pandas to get the minimum, average, middle, and maximum values of the \"prediction\" column in the edge_cases dataframe üêº\n",
    "edge_cases[\"prediction\"].min(), edge_cases[\"prediction\"].mean() , edge_cases[\"prediction\"].median(),edge_cases[\"prediction\"].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149af54",
   "metadata": {
    "papermill": {
     "duration": 0.011716,
     "end_time": "2024-01-14T05:30:54.631123",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.619407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explaination\n",
    "### Analyzing Edge Cases Distribution in Prediction Scores\n",
    "\n",
    "To gain insights into the distribution of edge cases and assess your model's confidence, you can utilize the `pd.cut()` function in Python's Pandas library. This approach allows you to categorize prediction scores into intervals and count the occurrences within each interval. The resulting output is a dataframe containing a column named \"prediction\" with five rows corresponding to the specified intervals.\n",
    "\n",
    "#### Usage Example:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'prediction_scores' is a column in your dataframe containing prediction scores\n",
    "intervals = [interval1, interval2, interval3, interval4, interval5]\n",
    "df['prediction'] = pd.cut(df['prediction_scores'], bins=intervals)\n",
    "\n",
    "# The resulting dataframe provides a breakdown of edge cases within each interval\n",
    "```\n",
    "\n",
    "This method helps you visualize and understand how your model performs across different prediction ranges. It's a valuable tool for assessing model confidence and identifying potential areas for improvement.\n",
    "\n",
    "üìö **Sources:**\n",
    "1. [Stack Overflow - Pandas how to use pd.cut()](https://stackoverflow.com/questions/45751390/pandas-how-to-use-pd-cut)\n",
    "2. [Pandas Documentation - pandas.cut()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html)\n",
    "3. [javatpoint - Pandas DataFrame.cut()](https://www.javatpoint.com/pandas-dataframe-cut)\n",
    "4. [Pandas Documentation (version 0.23.4) - pandas.cut()](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.cut.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e222631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:54.656355Z",
     "iopub.status.busy": "2024-01-14T05:30:54.656018Z",
     "iopub.status.idle": "2024-01-14T05:30:54.675430Z",
     "shell.execute_reply": "2024-01-14T05:30:54.674588Z"
    },
    "papermill": {
     "duration": 0.034132,
     "end_time": "2024-01-14T05:30:54.677483",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.643351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.4, 0.5]</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.3, 0.4]</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.2, 0.3]</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 0.2]</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.1]</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "prediction       \n",
       "(0.4, 0.5]    109\n",
       "(0.3, 0.4]     43\n",
       "(0.2, 0.3]     12\n",
       "(0.1, 0.2]      2\n",
       "(0.0, 0.1]      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the cut method of pandas to bin the \"prediction\" column in the edge_cases dataframe into five equal-width intervals from 0.0 to 0.5 üêº\n",
    "# The include_lowest argument is set to False, which means the first interval is open on the left (0.0, 0.1) and does not include 0.0\n",
    "# The value_counts method of pandas returns the frequency of each interval in the \"prediction\" column üìä\n",
    "pd.DataFrame(pd.cut(edge_cases['prediction'], [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], include_lowest=False).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ace0f",
   "metadata": {
    "papermill": {
     "duration": 0.011897,
     "end_time": "2024-01-14T05:30:54.701425",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.689528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explaination\n",
    "\n",
    "### Understanding Model Performance Metrics with metrics.json\n",
    "\n",
    "The `metrics.json` file serves as a repository of crucial information regarding your machine learning model's performance, specifically focusing on edge cases. It provides key metrics such as accuracy, precision, recall, and F1-score. üßÆ\n",
    "\n",
    "#### Utilizing metrics.json for Model Evaluation:\n",
    "\n",
    "By delving into the contents of this file, you can comprehensively assess how well your model handles edge cases. The metrics act as a guide, offering insights into areas where your model excels and areas that may require improvement. üöÄ\n",
    "\n",
    "#### Example Usage:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"accuracy\": 0.85,\n",
    "  \"precision\": 0.78,\n",
    "  \"recall\": 0.92,\n",
    "  \"f1-score\": 0.84,\n",
    "  // Additional metrics and information\n",
    "}\n",
    "```\n",
    "\n",
    "These metrics become valuable tools in refining and optimizing your machine learning model for enhanced performance.\n",
    "\n",
    "üìö **Sources:**\n",
    "1. [Stack Overflow - Prometheus json metrics](https://stackoverflow.com/questions/57844617/prometheus-json-metrics)\n",
    "2. [Azure Documentation - Send metrics to the Azure Monitor metric database](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-store-custom-rest-api)\n",
    "3. [Stack Overflow - Metrics reporting customization in Java](https://stackoverflow.com/questions/22803970/metrics-reporting-customization)\n",
    "4. [Stack Overflow - Obtaining Spark driver metrics in JSON](https://stackoverflow.com/questions/28083597/how-to-get-the-spark-driver-metrics-json)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf264bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:54.727395Z",
     "iopub.status.busy": "2024-01-14T05:30:54.727039Z",
     "iopub.status.idle": "2024-01-14T05:30:54.736782Z",
     "shell.execute_reply": "2024-01-14T05:30:54.735825Z"
    },
    "papermill": {
     "duration": 0.025253,
     "end_time": "2024-01-14T05:30:54.738825",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.713572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUC': 0.9985770475470891}\n"
     ]
    }
   ],
   "source": [
    "# Use the open function to read the file named \"metrics.json\" from the given path üìÇ\n",
    "with open(\"/kaggle/input/llm-daigt-find-edge-case/metrics.json\") as f:\n",
    "    # Use the json library to load the file content as a Python dictionary üìÑ\n",
    "    metrics = json.load(f)\n",
    "# Use the print function to display the metrics dictionary on the screen üñ•Ô∏è\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb422c0",
   "metadata": {
    "papermill": {
     "duration": 0.012206,
     "end_time": "2024-01-14T05:30:54.763549",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.751343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explaination\n",
    "\n",
    "\n",
    "\n",
    "#### Files Overview:\n",
    "\n",
    "1. **test_essays.csv:**\n",
    "   - Contains a set of 1000 essays that require classification as either human or machine-generated. üìù\n",
    "\n",
    "2. **sample_submission.csv:**\n",
    "   - Demonstrates the expected submission file format, comprising two columns: id and label. üóÉÔ∏è\n",
    "\n",
    "3. **train_v2_drcat_02.csv:**\n",
    "   - Encompasses a dataset of 2000 essays, accompanied by corresponding labels (0 for human, 1 for machine). This file serves as a training set to develop machine learning models for the detection of AI-generated text. üöÄ\n",
    "\n",
    "üìö **Sources:**\n",
    "\n",
    "- [How to use a train.csv, test.csv, and ground_truth.csv in machine learning models](https://stackoverflow.com/questions/39962836/how-to-use-a-train-csv-test-csv-and-ground-truth-csv-in-a-machine-learning-mod) \n",
    "- [Producing a Kaggle submission CSV file with specific entries](https://stackoverflow.com/questions/52411992/how-to-produce-a-kaggle-submission-csv-file-with-specific-entries) \n",
    "- [Using multiple CSV files as test and training sets for CNN](https://stackoverflow.com/questions/57148326/use-multiple-csv-files-as-test-and-training-set-for-cnn) \n",
    "- [Training a model from a CSV dataset with DeepDetect](https://www.deepdetect.com/server/docs/csv-training/) \n",
    "- [Kaggle Competition - Detect AI-generated Text](https://www.kaggle.com/kernels/scriptcontent/155514240/download) \n",
    "- [DeepDetect Example - Forest Type Dataset](http://www.deepdetect.com/dd/examples/all/forest_type/test.csv.tar.bz2) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5cd93e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:54.789904Z",
     "iopub.status.busy": "2024-01-14T05:30:54.789598Z",
     "iopub.status.idle": "2024-01-14T05:30:56.582885Z",
     "shell.execute_reply": "2024-01-14T05:30:56.581912Z"
    },
    "papermill": {
     "duration": 1.809527,
     "end_time": "2024-01-14T05:30:56.585389",
     "exception": false,
     "start_time": "2024-01-14T05:30:54.775862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the read_csv method of pandas to load the test_essays.csv file from the given path into a dataframe named test üêº\n",
    "test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "\n",
    "# Use the read_csv method of pandas to load the sample_submission.csv file from the given path into a dataframe named sub üêº\n",
    "sub = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')\n",
    "\n",
    "# Use the read_csv method of pandas to load the train_v2_drcat_02.csv file from the given path into a dataframe named train, using a comma as the separator üêº\n",
    "train = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\", sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c59a72",
   "metadata": {
    "papermill": {
     "duration": 0.012202,
     "end_time": "2024-01-14T05:30:56.610521",
     "exception": false,
     "start_time": "2024-01-14T05:30:56.598319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explaination:\n",
    "\n",
    " ### Data Cleaning for Duplicate Essays\n",
    "\n",
    "This code cell is essential for maintaining the integrity of the `train` dataframe by eliminating any duplicate essays that could potentially impact the machine learning model's performance. üßπ\n",
    "\n",
    "- The `drop_duplicates` method is used to remove rows with duplicate essays, considering only the 'essay' column.\n",
    "- The `keep='first'` parameter ensures that the first occurrence of a duplicate essay is retained.\n",
    "- The `reset_index` function is then applied to reindex the dataframe after removal of duplicates, ensuring a clean and continuous index.\n",
    "\n",
    "üìö **Sources:**\n",
    "\n",
    "- [Resetting index after calling pandas drop_duplicates](https://stackoverflow.com/questions/28885073/resetting-index-after-calling-pandas-drop-duplicates) \n",
    "- [How to reset the indices of remaining dataframe values after removing duplicates](https://stackoverflow.com/questions/62155590/how-to-reset-the-indices-of-remaining-dataframe-values-after-removing-duplicate) \n",
    "- [Index of Data after train and test split](https://stackoverflow.com/questions/53638231/index-of-data-after-train-and-test-split) \n",
    "- [How to Drop Duplicated Index in a Pandas DataFrame - A Complete Guide](https://saturncloud.io/blog/how-to-drop-duplicated-index-in-a-pandas-dataframe-a-complete-guide/) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6824d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:56.636641Z",
     "iopub.status.busy": "2024-01-14T05:30:56.636312Z",
     "iopub.status.idle": "2024-01-14T05:30:56.708009Z",
     "shell.execute_reply": "2024-01-14T05:30:56.707246Z"
    },
    "papermill": {
     "duration": 0.087071,
     "end_time": "2024-01-14T05:30:56.709977",
     "exception": false,
     "start_time": "2024-01-14T05:30:56.622906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the drop_duplicates method of pandas to remove any rows in the train dataframe that have the same value in the \"text\" column üêº\n",
    "# The subset argument specifies which column(s) to consider for identifying duplicates\n",
    "# The inplace argument is set to True, which means the original train dataframe is modified and no new dataframe is returned\n",
    "train = train.drop_duplicates(subset=['text'])\n",
    "\n",
    "# Use the reset_index method of pandas to reset the index of the train dataframe to a sequential numerical index üêº\n",
    "# The drop argument is set to True, which means the old index is dropped and not added as a new column\n",
    "# The inplace argument is set to True, which means the original train dataframe is modified and no new dataframe is returned\n",
    "train.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456d73ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:56.736692Z",
     "iopub.status.busy": "2024-01-14T05:30:56.736375Z",
     "iopub.status.idle": "2024-01-14T05:30:56.740895Z",
     "shell.execute_reply": "2024-01-14T05:30:56.740011Z"
    },
    "papermill": {
     "duration": 0.020145,
     "end_time": "2024-01-14T05:30:56.742920",
     "exception": false,
     "start_time": "2024-01-14T05:30:56.722775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# üö®üö®üö®\n",
    "# The following line of code sets the LOWERCASE flag to False.\n",
    "# This means that the text will not be converted to lowercase before tokenization.\n",
    "# üö®üö®üö®\n",
    "LOWERCASE = False\n",
    "\n",
    "# üö®üö®üö®\n",
    "# The following line of code sets the VOCAB_SIZE to 14000000.\n",
    "# This means that the maximum number of words in the vocabulary will be 14 million.\n",
    "# üö®üö®üö®\n",
    "VOCAB_SIZE = 140000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af7093",
   "metadata": {
    "papermill": {
     "duration": 0.012161,
     "end_time": "2024-01-14T05:30:56.767487",
     "exception": false,
     "start_time": "2024-01-14T05:30:56.755326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìë Byte-Pair Encoding Tokenizer Training¬∂\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "1. **Create Tokenizer Object:**\n",
    "   - Create a tokenizer using the Byte Pair Encoding (BPE) algorithm.\n",
    "   - Define an unknown token as \"[UNK]\".\n",
    "\n",
    "2. **Text Normalization:**\n",
    "   - Normalize the text using Unicode Normalization Form C (NFC).\n",
    "   - Optionally lowercase the text based on the condition.\n",
    "\n",
    "3. **Pre-tokenization:**\n",
    "   - Pre-tokenize the text by splitting it into bytes using the ByteLevel pre-tokenizer.\n",
    "\n",
    "4. **Special Tokens:**\n",
    "   - Define special tokens (e.g., \"[PAD]\", \"[CLS]\") for downstream tasks.\n",
    "\n",
    "5. **Trainer Object:**\n",
    "   - Create a trainer object for training the tokenizer.\n",
    "   - Set the vocabulary size and special tokens.\n",
    "\n",
    "6. **Load and Prepare Dataset:**\n",
    "   - Load the test dataset from a pandas dataframe, selecting only the 'text' column.\n",
    "\n",
    "7. **Batch Generation:**\n",
    "   - Define a generator function to yield batches of text from the dataset.\n",
    "\n",
    "8. **Tokenizer Training:**\n",
    "   - Train the tokenizer on batches of text using the trainer object.\n",
    "\n",
    "9. **Wrapper for HuggingFace:**\n",
    "   - Wrap the raw tokenizer into a PreTrainedTokenizerFast object compatible with HuggingFace.\n",
    "   - Define special tokens for compatibility.\n",
    "\n",
    "10. **Tokenization of Test Set:**\n",
    "    - Tokenize the texts in the test set using the tokenizer object.\n",
    "    - Store the tokenized texts in the 'tokenized_texts_test' list.\n",
    "\n",
    "11. **Tokenization of Train Set:**\n",
    "    - Tokenize the texts in the train set using the same tokenizer.\n",
    "    - Store the tokenized texts in the 'tokenized_texts_train' list.\n",
    "\n",
    "üìö **Sources:**\n",
    "\n",
    "1. [Byte Pair Encoding (BPE) Algorithm](https://arxiv.org/abs/1508.07909)\n",
    "2. [Unicode Normalization Forms](https://unicode.org/reports/tr15/)\n",
    "3. [HuggingFace Tokenizers Documentation](https://huggingface.co/docs/tokenizers/)\n",
    "4. [ByteLevel Pre-tokenizer](https://huggingface.co/docs/tokenizers/pretokenizers.html#bytetranslation-pretokenizer)\n",
    "5. [HuggingFace BPE Trainer](https://huggingface.co/docs/tokenizers/trainers.html#bpetrainer)\n",
    "6. [HuggingFace PreTrainedTokenizerFast](https://huggingface.co/docs/tokenizers/pretrained_tokenizer_fast.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc971f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:30:56.793473Z",
     "iopub.status.busy": "2024-01-14T05:30:56.793182Z",
     "iopub.status.idle": "2024-01-14T05:32:48.654957Z",
     "shell.execute_reply": "2024-01-14T05:32:48.654095Z"
    },
    "papermill": {
     "duration": 111.877163,
     "end_time": "2024-01-14T05:32:48.656995",
     "exception": false,
     "start_time": "2024-01-14T05:30:56.779832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd02399d1c94677a120793f2210ae93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2bcc5fa78546fdb5e9fe86eedadc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a tokenizer object using the Byte Pair Encoding (BPE) algorithm\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "# Normalize the text by applying Unicode Normalization Form C (NFC) and optionally lowercasing it\n",
    "raw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\n",
    "\n",
    "# Pre-tokenize the text by splitting it into bytes\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "\n",
    "# Define the special tokens that will be used for the downstream task\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "\n",
    "# Create a trainer object that will train the tokenizer on the given vocabulary size and special tokens\n",
    "trainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n",
    "\n",
    "# Load the test dataset from a pandas dataframe and select only the text column\n",
    "dataset = Dataset.from_pandas(test[['text']])\n",
    "\n",
    "# Define a generator function that will yield batches of text from the dataset\n",
    "def train_corp_iter(): \n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][\"text\"]\n",
    "\n",
    "# Train the tokenizer on the batches of text using the trainer object\n",
    "raw_tokenizer.train_from_iterator(train_corp_iter(), trainer=trainer)\n",
    "\n",
    "# Wrap the raw tokenizer object into a PreTrainedTokenizerFast object that is compatible with the HuggingFace library\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store the tokenized texts for the test set\n",
    "tokenized_texts_test = []\n",
    "\n",
    "# Loop over the texts in the test set and tokenize them using the tokenizer object\n",
    "for text in tqdm(test['text'].tolist()):\n",
    "    tokenized_texts_test.append(tokenizer.tokenize(text))\n",
    "\n",
    "# Initialize an empty list to store the tokenized texts for the train set\n",
    "tokenized_texts_train = []\n",
    "\n",
    "# Loop over the texts in the train set and tokenize them using the tokenizer object\n",
    "for text in tqdm(train['text'].tolist()):\n",
    "    tokenized_texts_train.append(tokenizer.tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a652b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:32:48.684515Z",
     "iopub.status.busy": "2024-01-14T05:32:48.684215Z",
     "iopub.status.idle": "2024-01-14T05:32:48.689898Z",
     "shell.execute_reply": "2024-01-14T05:32:48.689113Z"
    },
    "papermill": {
     "duration": 0.021427,
     "end_time": "2024-01-14T05:32:48.691705",
     "exception": false,
     "start_time": "2024-01-14T05:32:48.670278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ƒ†Bbb', 'ƒ†ccc', 'ƒ†ddd', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the second element (index 1) in the 'tokenized_texts_test' list üìö\n",
    "tokenized_texts_test[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d8fb2",
   "metadata": {
    "papermill": {
     "duration": 0.01273,
     "end_time": "2024-01-14T05:32:48.717258",
     "exception": false,
     "start_time": "2024-01-14T05:32:48.704528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìë TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0912643",
   "metadata": {
    "papermill": {
     "duration": 0.012917,
     "end_time": "2024-01-14T05:32:48.743083",
     "exception": false,
     "start_time": "2024-01-14T05:32:48.730166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation of the Code:\n",
    "\n",
    "1. **Define a Dummy Function:**\n",
    "   - A function named `dummy` is defined, which takes an input text and returns it as it is. This function will be used later in the TfidfVectorizer as a placeholder for tokenization.\n",
    "\n",
    "2. **Create TfidfVectorizer Object:**\n",
    "   - Instantiate a TfidfVectorizer object with the following configurations:\n",
    "     - `ngram_range=(3, 5)`: Extract n-grams of words with lengths ranging from 3 to 5.\n",
    "     - `lowercase=False`: Do not convert text to lowercase.\n",
    "     - `sublinear_tf=True`: Apply sublinear scaling to the term frequency.\n",
    "     - `analyzer='word'`: Analyze words.\n",
    "     - `tokenizer=dummy`: Use the previously defined dummy function for tokenization.\n",
    "     - `preprocessor=dummy`: Use the dummy function as a preprocessor.\n",
    "     - `token_pattern=None`: Do not use a specific token pattern.\n",
    "     - `strip_accents='unicode'`: Strip accents using Unicode.\n",
    "\n",
    "3. **Fit Vectorizer on Test Set:**\n",
    "   - Fit the vectorizer on the tokenized texts of the test set (`tokenized_texts_test`). This step generates a vocabulary of n-grams and their indices.\n",
    "\n",
    "4. **Get Vocabulary:**\n",
    "   - Obtain the vocabulary of the vectorizer, which is a dictionary mapping n-grams to their respective indices.\n",
    "\n",
    "5. **Print Vocabulary:**\n",
    "   - Print the obtained vocabulary.\n",
    "\n",
    "6. **Create Another Vectorizer with the Same Vocabulary:**\n",
    "   - Create a new TfidfVectorizer object with the same configurations as before but using the vocabulary obtained from the previous vectorizer.\n",
    "\n",
    "7. **Fit and Transform on Train Set:**\n",
    "   - Fit and transform the new vectorizer on the tokenized texts of the train set (`tokenized_texts_train`). This step produces a sparse matrix of tf-idf values for the train set.\n",
    "\n",
    "8. **Transform on Test Set:**\n",
    "   - Transform the new vectorizer on the tokenized texts of the test set, obtaining the sparse matrix of tf-idf values for the test set.\n",
    "\n",
    "9. **Memory Management:**\n",
    "   - Delete the vectorizer object to free up memory.\n",
    "   - Invoke the garbage collector to reclaim any unused memory.\n",
    "\n",
    "### Learning Sources:\n",
    "\n",
    "#### TfidfVectorizer and Text Vectorization:\n",
    "- **Scikit-Learn TfidfVectorizer Documentation**: [TfidfVectorizer Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "  - Understand the parameters and usage of TfidfVectorizer in Scikit-Learn.\n",
    "\n",
    "- **Understanding TF-IDF**: [TF-IDF Explained](https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/)\n",
    "  - Learn about the concept of TF-IDF and its application in text vectorization.\n",
    "\n",
    "#### Memory Management in Python:\n",
    "- **Memory Management in Python**: [Real Python - Memory Management](https://realpython.com/python-memory-management/)\n",
    "  - Explore how memory management works in Python and learn about garbage collection.\n",
    "\n",
    "#### N-grams and Tokenization:\n",
    "- **N-grams Explained**: [N-grams](https://en.wikipedia.org/wiki/N-gram)\n",
    "  - Understand the concept of n-grams in natural language processing.\n",
    "\n",
    "- **Tokenization in NLP**: [Natural Language Toolkit (NLTK) - Tokenization](https://www.nltk.org/book/ch03.html)\n",
    "  - Learn about tokenization, a crucial step in text processing, using NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79bd6e1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:32:48.813808Z",
     "iopub.status.busy": "2024-01-14T05:32:48.813166Z",
     "iopub.status.idle": "2024-01-14T05:34:13.701115Z",
     "shell.execute_reply": "2024-01-14T05:34:13.700109Z"
    },
    "papermill": {
     "duration": 84.960481,
     "end_time": "2024-01-14T05:34:13.716480",
     "exception": false,
     "start_time": "2024-01-14T05:32:48.755999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ƒ†Aaa ƒ†bbb ƒ†ccc .': 0, 'ƒ†Bbb ƒ†ccc ƒ†ddd .': 1, 'ƒ†CCC ƒ†ddd ƒ†eee .': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a dummy function that returns the input text as it is\n",
    "def dummy(text):\n",
    "    return text\n",
    "\n",
    "# Create a TfidfVectorizer object that will extract n-grams of words (3 to 5) from the text, without lowercasing or tokenizing it\n",
    "vectorizer = TfidfVectorizer(ngram_range=(4, 4), lowercase=False, sublinear_tf=True, analyzer = 'word',\n",
    "    tokenizer = dummy,\n",
    "    preprocessor = dummy,\n",
    "    token_pattern = None, strip_accents='unicode')\n",
    "\n",
    "# Fit the vectorizer on the tokenized texts of the test set\n",
    "vectorizer.fit(tokenized_texts_test)\n",
    "\n",
    "# Get the vocabulary of the vectorizer, which is a dictionary of n-grams and their indices\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "# Print the vocabulary\n",
    "print(vocab)\n",
    "\n",
    "# Create another TfidfVectorizer object with the same parameters, but using the vocabulary obtained from the previous vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(4, 4), lowercase=False, sublinear_tf=True, vocabulary=vocab,\n",
    "                            analyzer = 'word',\n",
    "                            tokenizer = dummy,\n",
    "                            preprocessor = dummy,\n",
    "                            token_pattern = None, strip_accents='unicode'\n",
    "                            )\n",
    "\n",
    "# Fit and transform the vectorizer on the tokenized texts of the train set, and get the sparse matrix of tf-idf values\n",
    "tf_train = vectorizer.fit_transform(tokenized_texts_train)\n",
    "\n",
    "# Transform the vectorizer on the tokenized texts of the test set, and get the sparse matrix of tf-idf values\n",
    "tf_test = vectorizer.transform(tokenized_texts_test)\n",
    "\n",
    "# Delete the vectorizer object to free up memory\n",
    "del vectorizer\n",
    "\n",
    "# Invoke the garbage collector to reclaim unused memory\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d51bba3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:34:13.744732Z",
     "iopub.status.busy": "2024-01-14T05:34:13.744413Z",
     "iopub.status.idle": "2024-01-14T05:34:13.748659Z",
     "shell.execute_reply": "2024-01-14T05:34:13.747912Z"
    },
    "papermill": {
     "duration": 0.020448,
     "end_time": "2024-01-14T05:34:13.750478",
     "exception": false,
     "start_time": "2024-01-14T05:34:13.730030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = train['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b902b",
   "metadata": {
    "papermill": {
     "duration": 0.013061,
     "end_time": "2024-01-14T05:34:13.776969",
     "exception": false,
     "start_time": "2024-01-14T05:34:13.763908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training and Prediction¬∂\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5abb8b",
   "metadata": {
    "papermill": {
     "duration": 0.01317,
     "end_time": "2024-01-14T05:34:13.803464",
     "exception": false,
     "start_time": "2024-01-14T05:34:13.790294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Explanation of the Code:\n",
    "\n",
    "1. **Define Ensemble Model:**\n",
    "   - A function named `get_model` is defined to create an ensemble model using four different classifiers: Multinomial Naive Bayes, Stochastic Gradient Descent, LightGBM, and CatBoost. The ensemble model is a VotingClassifier that combines these classifiers using soft voting.\n",
    "\n",
    "2. **Import Libraries and Classifiers:**\n",
    "   - The CatBoostClassifier is imported from the CatBoost library.\n",
    "   - Multinomial Naive Bayes (MNB), Stochastic Gradient Descent (SGD), LightGBM (LGBM), and CatBoost classifiers are created with specific configurations.\n",
    "\n",
    "3. **Configure Classifier Parameters:**\n",
    "   - Parameters for the classifiers are set, including alpha for MNB, max_iter, tol, loss function for SGD, and various parameters for LightGBM and CatBoost.\n",
    "\n",
    "4. **Define Voting Classifier:**\n",
    "   - A list of weights for each classifier is defined.\n",
    "   - A VotingClassifier is created, combining the four classifiers with soft voting. The ensemble model is configured to use parallel processing.\n",
    "\n",
    "5. **Call the `get_model` Function:**\n",
    "   - The `get_model` function is called, and the returned ensemble model is assigned to a variable named `model`.\n",
    "\n",
    "6. **Print the Model:**\n",
    "   - The ensemble model is printed.\n",
    "\n",
    "7. **Check Length of Test Text Values:**\n",
    "   - If the length of the test text values is less than or equal to 5, the code saves the submission dataframe to a CSV file and ends.\n",
    "\n",
    "8. **Fit Model and Predict:**\n",
    "   - If the length of the test text values is greater than 5, the model is fitted on the TF-IDF matrix of the train set and the target labels.\n",
    "   - The garbage collector is invoked to reclaim any unused memory.\n",
    "   - The model predicts the probabilities of the positive class for the test set using the TF-IDF matrix.\n",
    "   - The predicted probabilities are assigned to a new column in the submission dataframe.\n",
    "\n",
    "9. **Save and Display Results:**\n",
    "   - The submission dataframe is saved to a CSV file.\n",
    "   - If the length of the test text values is greater than 5, the submission dataframe is displayed.\n",
    "\n",
    "### Learning Sources:\n",
    "\n",
    "#### Ensemble Learning and Classifiers:\n",
    "- **Ensemble Learning - Scikit-Learn**: [Ensemble Methods](https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "  - Understand the concept of ensemble learning and how it can improve model performance.\n",
    "\n",
    "- **CatBoost Documentation**: [CatBoost Documentation](https://catboost.ai/docs/)\n",
    "  - Explore the official documentation for CatBoost to learn about its features and usage.\n",
    "\n",
    "- **LightGBM Documentation**: [LightGBM Documentation](https://lightgbm.readthedocs.io/en/latest/)\n",
    "  - Learn about LightGBM, a gradient boosting framework that is efficient and scalable.\n",
    "\n",
    "- **Scikit-Learn - Multinomial Naive Bayes**: [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes)\n",
    "  - Understand the Multinomial Naive Bayes classifier in Scikit-Learn.\n",
    "\n",
    "- **Scikit-Learn - Stochastic Gradient Descent (SGD)**: [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "  - Explore the SGDClassifier in Scikit-Learn, which is used for training linear classifiers.\n",
    "\n",
    "#### Memory Management in Python:\n",
    "- **Memory Management in Python**: [Real Python - Memory Management](https://realpython.com/python-memory-management/)\n",
    "  - Learn about how memory management works in Python and the importance of garbage collection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95e47d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T05:34:13.831508Z",
     "iopub.status.busy": "2024-01-14T05:34:13.831217Z",
     "iopub.status.idle": "2024-01-14T05:34:14.156492Z",
     "shell.execute_reply": "2024-01-14T05:34:14.155445Z"
    },
    "papermill": {
     "duration": 0.3418,
     "end_time": "2024-01-14T05:34:14.158572",
     "exception": false,
     "start_time": "2024-01-14T05:34:13.816772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('mnb', MultinomialNB(alpha=0.0235)),\n",
      "                             ('sgd',\n",
      "                              SGDClassifier(loss='modified_huber',\n",
      "                                            max_iter=9000, random_state=6743,\n",
      "                                            tol=0.0003)),\n",
      "                             ('lgb',\n",
      "                              LGBMClassifier(colsample_bynode=0.8,\n",
      "                                             colsample_bytree=0.78,\n",
      "                                             learning_rate=0.0031909898961407,\n",
      "                                             metric='auc', n_iter=3000,\n",
      "                                             objective='cross_entropy',\n",
      "                                             random_state=6743, verbose=-1)),\n",
      "                             ('cat',\n",
      "                              <catboost.core.CatBoostClassifier object at 0x7ac3002e0d30>)],\n",
      "                 n_jobs=-1, voting='soft', weights=[0.1, 0.31, 0.31, 0.6])\n"
     ]
    }
   ],
   "source": [
    "# Define a function that returns an ensemble model of four classifiers\n",
    "def get_model():\n",
    "    # Import the CatBoostClassifier from the catboost library\n",
    "    from catboost import CatBoostClassifier\n",
    "    \n",
    "    # Create a Multinomial Naive Bayes classifier with a smoothing parameter of 0.0235\n",
    "    clf = MultinomialNB(alpha=0.0235)\n",
    "    \n",
    "    # Create a Stochastic Gradient Descent classifier with a maximum of 9000 iterations, a tolerance of 3e-4, a modified huber loss function, and a random state of 6743\n",
    "    sgd_model = SGDClassifier(max_iter=9000, tol=3e-4, loss=\"modified_huber\", random_state=6743) \n",
    "    \n",
    "    # Define a dictionary of parameters for a LightGBM classifier\n",
    "    p6={'n_iter': 3000,'verbose': -1,'objective': 'cross_entropy','metric': 'auc',\n",
    "        'learning_rate': 0.0031909898961407, 'colsample_bytree': 0.78,\n",
    "        'colsample_bynode': 0.8,\n",
    "       }\n",
    "    \n",
    "    # Set the random state of the LightGBM classifier to 6743\n",
    "    p6[\"random_state\"] = 6743\n",
    "    \n",
    "    # Create a LightGBM classifier with the given parameters\n",
    "    lgb=LGBMClassifier(**p6)\n",
    "    \n",
    "    # Create a CatBoost classifier with 3000 iterations, a learning rate of 0.003599066836106983, a subsample of 0.4, a cross entropy loss function, and a random seed of 6543\n",
    "    cat=CatBoostClassifier(iterations=3000,\n",
    "                           verbose=0,\n",
    "                           random_seed=6543,\n",
    "                           learning_rate=0.003599066836106983,\n",
    "                           subsample = 0.4,\n",
    "                           allow_const_label=True,loss_function = 'CrossEntropy')\n",
    "    \n",
    "    # Define a list of weights for the four classifiers\n",
    "    weights = [0.1,0.31,0.31,0.6]\n",
    " \n",
    "    # Create a voting classifier that combines the four classifiers using soft voting and parallel processing\n",
    "    ensemble = VotingClassifier(estimators=[('mnb',clf),\n",
    "                                            ('sgd', sgd_model),\n",
    "                                            ('lgb',lgb), \n",
    "                                            ('cat', cat)\n",
    "                                           ],\n",
    "                                weights=weights, voting='soft', n_jobs=-1)\n",
    "    \n",
    "    # Return the ensemble model\n",
    "    return ensemble\n",
    "\n",
    "# Call the get_model function and assign the returned model to a variable\n",
    "model = get_model()\n",
    "\n",
    "# Print the model\n",
    "print(model)\n",
    "\n",
    "# Check the length of the test text values\n",
    "if len(test.text.values) <= 5:\n",
    "    # If the length is less than or equal to 5, save the submission dataframe to a csv file\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "else:\n",
    "    # Otherwise, fit the model on the tf-idf matrix of the train set and the target labels\n",
    "    model.fit(tf_train, y_train)\n",
    "\n",
    "    # Invoke the garbage collector to reclaim unused memory\n",
    "    gc.collect()\n",
    "\n",
    "    # Predict the probabilities of the positive class for the test set using the model\n",
    "    final_preds = model.predict_proba(tf_test)[:,1]\n",
    "    \n",
    "    # Assign the predicted probabilities to the generated column of the submission dataframe\n",
    "    sub['generated'] = final_preds\n",
    "    \n",
    "    # Save the submission dataframe to a csv file\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    # Display the submission dataframe\n",
    "    sub\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 4005256,
     "sourceId": 6977472,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4099711,
     "sourceId": 7110479,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4104703,
     "sourceId": 7117339,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 155681847,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 215.452032,
   "end_time": "2024-01-14T05:34:16.993715",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-14T05:30:41.541683",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "07be77fecbfc47bba9470ff3d7146346": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "161d2b098bff4a1bb1ea1aa3a1b7ebdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1a2bcc5fa78546fdb5e9fe86eedadc59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3ec5b567c67d48ee85d28c6b94e93225",
        "IPY_MODEL_e3e040a37f3f4fb7879241870f91ea4e",
        "IPY_MODEL_5b8c8c97f8174e519808fccd1c28cebe"
       ],
       "layout": "IPY_MODEL_3d3ba3d373574decbd7c4facef50cdc5"
      }
     },
     "3bbb7d58905b4fafa18e9e035e492bca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3d3ba3d373574decbd7c4facef50cdc5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ec5b567c67d48ee85d28c6b94e93225": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8744502f26354787af4be3b7eb92f7b1",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_c300f52d67ea46da965051c8f97602d9",
       "value": "100%"
      }
     },
     "4dd02399d1c94677a120793f2210ae93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b421e475e2024c68ab683283b75a2169",
        "IPY_MODEL_624d8233f3f3482086a03f47555a6d3b",
        "IPY_MODEL_ef02324736dd4a98a26973db983a86b4"
       ],
       "layout": "IPY_MODEL_d0e256effa584037b2122dac47f46bf8"
      }
     },
     "4fc57d2ecb094a019fa538c76c132989": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5b8c8c97f8174e519808fccd1c28cebe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f90da06edf8e42d695f97a2cf9391e9d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_4fc57d2ecb094a019fa538c76c132989",
       "value": " 44868/44868 [01:51&lt;00:00, 410.78it/s]"
      }
     },
     "624d8233f3f3482086a03f47555a6d3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb8350ad5bc54fc6b2769e7b31dce454",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5272dd83a4f4c1fb7e04c816e31de1f",
       "value": 3.0
      }
     },
     "744fbcbc0df0448dbc411294b7feae5e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8744502f26354787af4be3b7eb92f7b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "921bc11a3c2e482c999918e9007183a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b421e475e2024c68ab683283b75a2169": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c081b3dc786247bf9a01ee30acb7ed08",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_161d2b098bff4a1bb1ea1aa3a1b7ebdf",
       "value": "100%"
      }
     },
     "c081b3dc786247bf9a01ee30acb7ed08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c300f52d67ea46da965051c8f97602d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cb8350ad5bc54fc6b2769e7b31dce454": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0e256effa584037b2122dac47f46bf8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3e040a37f3f4fb7879241870f91ea4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_744fbcbc0df0448dbc411294b7feae5e",
       "max": 44868.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_07be77fecbfc47bba9470ff3d7146346",
       "value": 44868.0
      }
     },
     "ef02324736dd4a98a26973db983a86b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_921bc11a3c2e482c999918e9007183a2",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_3bbb7d58905b4fafa18e9e035e492bca",
       "value": " 3/3 [00:00&lt;00:00, 231.84it/s]"
      }
     },
     "f5272dd83a4f4c1fb7e04c816e31de1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f90da06edf8e42d695f97a2cf9391e9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
